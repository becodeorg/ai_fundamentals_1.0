{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does a neural network learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is goes to cover how a neural network learns.\n",
    "\n",
    "### Forward pass\n",
    "In the previous section, you saw the definition of a single neuron from a neural network.\n",
    "You also saw how you could stack many neurons on top of each other to create a layer, and how you could create a *multi-layer* network by putting multiple layers in parallel.\n",
    "\n",
    "The passing of information from the inputs of the neural network, through each layer up until the end, is called the **forward pass**.\n",
    "\n",
    "In essence, the **forward pass** is simply combining the inputs of each neuron by computing a weighted sum and passing it through an activation function. And this, for every neuron of every layer.\n",
    "\n",
    "### Backward pass\n",
    "Now, at the moment, the neural network does nothing. It has just computed some values for each input, but once it has done all of this, nothing changes.\n",
    "Indeed, it now needs to learn. This is the task of the **backward pass**.\n",
    "\n",
    "However, we have to ask ourselves what the neural network is supposed to do.\n",
    "Indeed, it is all fine to show all this theoretical information, but **what are we trying to build here ?**\n",
    "\n",
    "The neural network is supposed to **learn the relationship between the input we give it and the corresponding output**. Afterwards, when given inputs that it has never seen, it should be able to predict the corresponding output correctly.\n",
    "\n",
    "\n",
    "\n",
    "For this, let's recap some stuff that we saw in the *Regression track*. That is, let's review (in a bit more detail), the cost function and gradient descent.\n",
    "\n",
    "* * *\n",
    "* * *\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "The cost function allows us to **evaluate the performance of our model** by measuring the errors between the prediction and the actual value. The question we ask ourselves is: *How to measure these errors?*\n",
    "\n",
    "**One way** to measure the error is to compute the squared difference between the predicted value and the true value. Namely, if $x$ is our input, $f(x)$ is the predicted output, and $y$ is the true output, we have the error $e$:\n",
    "\n",
    "$$ e = (f(x) - y)^2 $$ \n",
    "\n",
    "\n",
    "The *cost function*  $C$ is the sum of the errors over all inputs samples, and it is defined by all the weights.\n",
    "For illustration purposes, instead of using all the weights, let's reduce the complexity of the cost function by defining it using only a single weight $w$ to be able to display it in 2D. As such, the cost function is defined as :\n",
    "\n",
    "$$ C(w) $$\n",
    "\n",
    "$C(w)$ gives us the cost of the model over all input samples at a given weight $w$.\n",
    "\n",
    "* * *\n",
    "* * *\n",
    "* * *\n",
    "\n",
    "\n",
    "\n",
    "Remember when, *in linear regression*, the cost function was a nice parabola.\n",
    "\n",
    "If you look at the graph below, it is not the case anymore (Let's forget the rolling balls for a second). Although the cost function in a neural network has an optimal solution, it has multiple sub-optimal solutions, i.e. multiple minima, whereas in linear regression, there is only one solution, e.g. one way to put the line so that it best fits every point.\n",
    "\n",
    "Some of them are local minima (sub-optimal solutions), and only one of them is global (optimal solution). The global minimum is the smallest value of the graph, while local minima are the smallest values in a particular region of space. The mathematical term for a function with multiple minima is *non-convex* (no, you don't have to remember that word).\n",
    "\n",
    "Finding the optimal solution is very hard, because the local minima share a lot of properties with the global minimum.\n",
    "\n",
    "In the graph below, you see 2 local minima and one global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient descend in 2D (GIF)](./assets/gradient_descent_2D.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *\n",
    "* * *\n",
    "\n",
    "So, just before we said that to measure the error, we would need to compute the squared difference between the predicted output and the true output.\n",
    "\n",
    "The graph below shows again how the *output value of a neuron* (here, 0.2) is computed. \n",
    "It is extracted from a video where the purpose of the neural network is to predict, from a handwritten digit (0-9), the digit that is written. The digit to be recognized in this scenario is the digit 2.\n",
    "\n",
    "* * *\n",
    "\n",
    "We multiply every input $a_i$ of that neuron with a weight $w_i$, add a bias term $b$ and pass it through an activation function $\\sigma$ (sigma) here for the *sigmoid* activation function.\n",
    "\n",
    "Note again that the output value of 0.2 is between 0 and 1 if we use a sigmoid. 1 meaning full activation and 0 meaning zero activation. Thus, it can be seen as a confidence value (in some sense).\n",
    "In this case, the model is shown an image of the digit 2 (not depicted here) and, through a combination of math, decides that the output of the neuron shall be 0.2 i.e. not very activated. **The model thinks that the image is not likely to be a 2, while it actually is.**\n",
    "\n",
    "**So, the goal of the neural network is to update the weights so that the 0.2 is increased to 1 (for that particular image it saw)**. The blue arrow near the output neuron signifies that. This will decrease the cost, which is the whole goal of this, **minimizing the cost function**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decomposition of weights over last layer (GIF)](./assets/last_layer_decomposition.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *\n",
    "* * *\n",
    "\n",
    "### Minimizing the cost function (Overview)\n",
    "\n",
    "However, the model has many outputs. In fact, one for each digit. **What we want is that, if the model sees an image of a 2, only the output neuron of the value 2 is 1 and the rest are 0.** Thus, for every other output neuron, the output value of that neuron has to decrease, shown here as the red downward facing arrows near the output neurons.\n",
    "\n",
    "As we saw just before, the output of a neuron is determined by the inputs to the neuron. **Thus, for every output neuron, all weights connecting to the input neuron have to be changed, one way or the other.**\n",
    "As we have multiple output neurons, each have a say on how the input neurons are changed. For every input neuron, we're going to sum up all the nudges and apply that summed-up change to the weights.\n",
    "\n",
    "* * *\n",
    "\n",
    "If you have followed along well, you are probably asking yourself. \"*Don't the input neurons have to change too?*\".\n",
    "And that is exactly right!\n",
    "What we've done here for the output neurons has to be done for every neuron, all the way up until the input neurons of the model. This is called **backpropagation**, because we are *propagating the change all the way from the output neurons to the input neurons of the neural network*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sum of nudges (GIF)](./assets/sum_of_nudges.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, that was all for a single image. We have to do that for all training data.\n",
    "After doing that for every single weight of the neural network, we take the average and update the weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Average nudge over all training samples (GIF)](./assets/average_over_all_training_data.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "* * *\n",
    "* * *\n",
    "\n",
    "When creating a neural network, the weights are initialized at random, so we will start at any random point on the curve.\n",
    "\n",
    "![Gradient descend in 2D (GIF)](./assets/gradient_descent_2D.gif)\n",
    "\n",
    "Each blue dot on the above GIF represent a possible input value (i.e. a weight) to the cost function. You can imagine the minimizing of a cost function to be like balls running down a hill. There are many different valleys you mind end up in, depending on where the input value start. There is no guarantee that the local minimum you end up in is the smallest value of the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extending the definition of the cost function to 3D space (e.g. two parameters characterizing the cost function), we can have the following graph. The same rules apply here as the 2D case.\n",
    "\n",
    "![Gradient descent 3D (GIF)](./assets/gradient_descent_3D.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizing the cost function (Details)\n",
    "\n",
    "\n",
    "The whole goal of the neural network is that it learns. And what is learning ? Well, it is learning by trying, just like BeCode juniors!\n",
    "\n",
    "Indeed, the network will need to learn from it's errors and make fewer and fewer errors as time goes on. In other words, need to **minimize the cost function**.\n",
    "\n",
    "You have been given a global overview of what minimizing the cost function represents in the previous cells. Here, we are going to tie the notions that you've seen just now with another notion that you know, **gradient descent**.\n",
    "\n",
    "#### Gradient and gradient descent\n",
    "\n",
    "![Gradient descent](./assets/gradient_descent_1.gif)\n",
    "One of the most popular algorithm for minimizing the cost function is called gradient descent.\n",
    "\n",
    "Remember how we computed the slope of a line with a [partial derivative](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/introduction-to-partial-derivatives) ? The symbol used to denote partial derivatives is $\\partial$. \n",
    "\n",
    "For example, for a line of formula $y = ax + b$, the partial derivative of $y$ with respect to $x$ is written as\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial x} = a$$ \n",
    "\n",
    "which yields $a$, the slope of the line.\n",
    "\n",
    "**Well, applying a gradient is simply doing a partial derivative with respect to every parameter.**\n",
    "\n",
    "For example, if we take the same line formula as above, and we compute the gradient, we get\n",
    "\n",
    "$$\\nabla f =  \\begin{bmatrix}\n",
    "               \\frac{\\partial y}{\\partial x} \\\\\n",
    "               \\frac{\\partial y}{\\partial a} \\\\\n",
    "               \\frac{\\partial y}{\\partial b}\n",
    "         \\end{bmatrix} =  \\begin{bmatrix}\n",
    "               a \\\\\n",
    "               x \\\\\n",
    "               1\n",
    "         \\end{bmatrix}$$\n",
    "(Taking the gradient of the line formula is mathematically not correct, but it is great for illustrative purposes)\n",
    "         \n",
    "Now, in itself, this is not useful for you. \n",
    "What you should know however is that the gradient tells us the **direction of most important positive change**.\n",
    "How does that apply here ? Well, we want to find the quickest way to the minimum. Thus, we want to find the direction which will drive us towards it. Well, this is the direction of most important *negative* change. \n",
    "Hence, for any point on the cost function surface, we can compute the **negative of the gradient** to get this direction, i.e. $-\\nabla C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And the gradient is effectively the exact thing we saw before. It is the average change over all training samples that we have to apply to each weight.**\n",
    "\n",
    "However, instead of changing the weights for that complete amount, we are going to do a tiny step in that direction. The tiny step is here is represented by $\\eta$, which is the **learning rate**. We are going to repeat this over and over until the model has learned to recognize the digits the best it possibly can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradients are the average nudges over all training samples (GIF)](./assets/gradient_is_average.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had a hard time following this material, don't worry. We highly suggest you to watch the following videos, which explains the topic way better than we could in a few Jupyter notebooks.\n",
    "\n",
    "### Additional reading material\n",
    "\n",
    "\n",
    "[Video: 3blue1brown - Gradient descent](https://youtu.be/IHZwWFHWa-w)\n",
    "\n",
    "[Video: 3blue1brown - Backpropagation](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    "\n",
    "[Article: Neural Network and backpropagation explained simply](https://medium.com/datathings/neural-networks-and-backpropagation-explained-in-a-simple-way-f540a3611f5e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
