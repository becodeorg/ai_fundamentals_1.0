{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic data collection on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start to tackle some nice web pages (html), we will discover the XML language which is a good introduction to data web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lists a few properties of the XML language.\n",
    "\n",
    "- XML was created to facilitate data exchange between machines and software.\n",
    "\n",
    "- XML is a language that is written using tags.\n",
    "\n",
    "- XML is a W3C recommendation, so it is a technology with strict rules to follow.\n",
    "\n",
    "- XML is intended to be understandable by everyone: people and machines alike.\n",
    "\n",
    "- XML allows us to create our own vocabulary using a set of customizable rules and tags.\n",
    "\n",
    "- XML is also compatible with the web so that data exchanges can be easily carried out over the Internet.\n",
    "\n",
    "- XML is therefore standardized, simple, but above all extensible and configurable so that any type of data can be described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a XML document, which we have saved as `data.xml` in the `assets/` directory.\n",
    "\n",
    "Display its content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./assets/data.xml\"\n",
    "file = open(filename, \"r\")\n",
    "print (file.read())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line indicates the encoding, we always stay in the UTF-8 encoding. Then we notice that the \"users\" tag has other \"user\" tags that themselves have their own tags. The data is hierarchized in a tree and each node provides information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a small script that displays all the usernames.\n",
    "\n",
    "You will first have to install the `lxml` package. It depends on the `numpy` package, which will be installed alongside `lxml` if you use a standard package manager. However, some version of `numpy` give problems, so changing the version might be the first thing that you can troubleshoot if you fail to import `lxml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "# I define my source document\n",
    "tree = etree.parse(filename)\n",
    "# I look at my document and identify the tag path to get to the \"user\" information\n",
    "# Indeed, the information is in a name tag itself present in a user tag\n",
    "# it even presents itself in a users tag. This last tag is located at the root of the directory\n",
    "# so in tree.xpath(\"/users/user/name\") there are the tags associated with our search\n",
    "for user in tree.xpath(\"/users/user/nom\"):\n",
    "    # I want to display only the content (.text) of these tags /users/user/name\n",
    "    print(user.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.xpath(\"/users/user/nom\")[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can display the attributes of the tags that store this information\n",
    "tree = etree.parse(filename)\n",
    "for user in tree.xpath(\"/users/user\"):\n",
    "    print(user.get(\"data-id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can refine the display by proposing to display only users whose job is Veterinary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse(filename)\n",
    "# Quel joli petit dictionnaire\n",
    "for user in tree.xpath(\"/users/user[metier='Veterinaire']/nom\"):\n",
    "    print(user.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data web scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, you will have to download `beautifulsoup4` using\n",
    "\n",
    "`pip install beautifulsoup4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw earlier how to parse XML, it is also possible to **parse HTML** and the tool that does the job best in my opinion is the `beautifulsoup` librairy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a web page (for example `www.becode.org`) that you like in the `./assets` directory, and display its content (the `.html` file)\n",
    "\n",
    "Put the content of this page in a variable, for example `html_doc`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "becode_filename = \"./assets/becode.html\"\n",
    "file = open(becode_filename, \"r\")\n",
    "\n",
    "html_doc=file.read()\n",
    "file.close()\n",
    "html_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")\n",
    "# In my file (becode.org) by looking at this html script We can see that the main title is arranged in the h1 tag\n",
    "\n",
    "for p in soup.find_all('h1'):\n",
    "    # We only retrieve the content ==> .text\n",
    "    print (p.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with H2 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, do the same with the \"p\" tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping via request HTTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP is a kind of language that will allow the client (you, through your browser for example) to communicate with a server connected to the network (the HTTP server installed on a site's server, for example Apache).\n",
    "\n",
    "Requests always go in pairs: the request (from the client) and the response (from the server).\n",
    "If this is not the case, it is because a problem has occurred at a point in the network.\n",
    "\n",
    "The syntax of the request (= client request) is always the same and is the following\n",
    "\n",
    "Command line (`command`, `URL`, `Protocol version`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`command` is the method to use, it specifies the type of request, it can have the values :\n",
    "\n",
    "\n",
    "- `\"GET\"`\n",
    "This is the most common way to request a resource. A GET request has no effect on the resource, it must be possible to repeat the request without effect.\n",
    "\n",
    "\n",
    "- `\"HEAD\"`\n",
    "This method only asks for information about the resource (the header), without asking for the resource itself.\n",
    "\n",
    "\n",
    "- `\"POST\"`\n",
    "This method must be used when a request modifies the resource.\n",
    "\n",
    "\n",
    "- `\"OPTIONS\"`\n",
    "This method allows you to obtain the communication options of a resource or the server in general.\n",
    "\n",
    "\n",
    "- `\"CONNECT\"`\n",
    "This method allows you to use a proxy as a communication tunnel.\n",
    "\n",
    "\n",
    "- `\"TRACE\"`\n",
    "This method asks the server to return what it has received, in order to test and diagnose the connection.\n",
    "\n",
    "\n",
    "- `\"PUT\"`\n",
    "This method allows you to add a resource to the server.\n",
    "\n",
    "\n",
    "- `\"DELETE\"`\n",
    "This method allows you to delete a resource from the server.\n",
    "\n",
    "I will only discuss the most common ones here: HEAD, GET and POST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it into practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Url of website\n",
    "url='https://www.becode.org/about/'\n",
    "# I send my HTTP request with a \"GET\" to the site server to identify in the url\n",
    "r = requests.get(url)\n",
    "# I display the requested url and the return of the server\n",
    "print(url, r.status_code)\n",
    "# I ask beautifulSoup to keep in a soup variable the web page to scrape (url) an html script\n",
    "soup = BeautifulSoup(r.content,'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have thus retrieved the information from the site without physically saving it in a file, only in a variable!\n",
    "\n",
    "Display the main title, the subtitles of and the paragraphs and their descriptions again to convince you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
